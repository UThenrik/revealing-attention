{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import scipy\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Project-specific imports\n",
    "sys.path.insert(0, './atarihead')\n",
    "sys.path.insert(0, '../src')\n",
    "from replay_buffer import HDF5ReplayBufferRAM\n",
    "from models import Autoencoder, Gaze_predictor_pool, Motor_predictor_fwd, CTR_Attention_dil, CTR_Attention_SA\n",
    "from utils import get_lr\n",
    "from training import Attention_training_class\n",
    "\n",
    "# External analysis functions\n",
    "import FUNCTIONS_Analysis as func_a\n",
    "\n",
    "# Configuration\n",
    "pd.options.display.float_format = '{:.3g}'.format\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "# IPython display setup\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Replay buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = [\n",
    "    'Alien', 'Asterix', 'BankHeist', 'Berzerk', 'Breakout',\n",
    "    'Centipede', 'DemonAttack', 'Enduro', 'Freeway', 'Frostbite',\n",
    "    'Hero', 'MontezumaRevenge', 'MsPacman', 'NameThisGame', 'Phoenix',\n",
    "    'Riverraid', 'RoadRunner', 'Seaquest', 'SpaceInvaders', 'Venture'\n",
    "]\n",
    "\n",
    "n_actions = {\n",
    "    'Alien': 18,\n",
    "    'Asterix': 9,\n",
    "    'BankHeist': 18,\n",
    "    'Berzerk': 18,\n",
    "    'Breakout': 4,\n",
    "    'Centipede': 18,\n",
    "    'DemonAttack': 6,\n",
    "    'Enduro': 9,\n",
    "    'Freeway': 3,\n",
    "    'Frostbite': 18,\n",
    "    'Hero': 18,\n",
    "    'MontezumaRevenge': 18,\n",
    "    'MsPacman': 9,\n",
    "    'NameThisGame': 6,\n",
    "    'Phoenix': 8,\n",
    "    'Riverraid': 18,\n",
    "    'RoadRunner': 18,\n",
    "    'Seaquest': 18,\n",
    "    'SpaceInvaders': 6,\n",
    "    'Venture': 18\n",
    "}\n",
    "\n",
    "AA_to_AH = {\n",
    "    'Alien': 'alien',\n",
    "    'Asterix': 'asterix',\n",
    "    'BankHeist': 'bank_heist',\n",
    "    'Berzerk': 'berzerk',\n",
    "    'Breakout': 'breakout',\n",
    "    'Centipede': 'centipede',\n",
    "    'DemonAttack': 'demon_attack',\n",
    "    'Enduro': 'enduro',\n",
    "    'Freeway': 'freeway',\n",
    "    'Frostbite': 'frostbite',\n",
    "    'Hero': 'hero',\n",
    "    'MontezumaRevenge': 'montezuma_revenge',\n",
    "    'MsPacman': 'ms_pacman',\n",
    "    'NameThisGame': 'name_this_game',\n",
    "    'Phoenix': 'phoenix',\n",
    "    'Riverraid': 'riverraid',\n",
    "    'RoadRunner': 'road_runner',\n",
    "    'Seaquest': 'seaquest',\n",
    "    'SpaceInvaders': 'space_invaders',\n",
    "    'Venture': 'venture'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for training\n",
    "config = {\n",
    "    \"game_name\": 'Freeway',  # Change as needed\n",
    "    \"train_val_split\": 0.8,\n",
    "    \"CTR_type\": \"dil\",  # Self-Attention: \"SA\", or Dilated CNN: \"dil\"\n",
    "    \"psi_blend_dropout\": 0.25,\n",
    "    \"train_additional_MPs\": True,  # Whether to concurrently train additional plain and GP motor predictor\n",
    "    \"n_epochs\": 300,  # higher\n",
    "    \"n_epochs_CTR\": 250,\n",
    "}\n",
    "\n",
    "# Load replay buffers\n",
    "memoryAA = HDF5ReplayBufferRAM.load(\n",
    "    file_path=f'replay_buffers/atari_agents/{config[\"game_name\"]}_atari_agents_buffer_4f_84gray.h5',\n",
    "    file_rw_option='r', \n",
    "    train_val_split=config[\"train_val_split\"], \n",
    "    RAM_ratio=1/1\n",
    ")\n",
    "memoryAH = HDF5ReplayBufferRAM.load(\n",
    "    file_path=f'replay_buffers/atarihead/{AA_to_AH[config[\"game_name\"]]}_atarihead_buffer_all_4f_84gray.h5',\n",
    "    file_rw_option='r', \n",
    "    train_val_split=config[\"train_val_split\"], \n",
    "    RAM_ratio=1/1\n",
    ")\n",
    "\n",
    "# Game configuration\n",
    "game_res = (210, 160, 3)\n",
    "game_max_reward = 1 \n",
    "game_n_actionsAH = 18\n",
    "game_n_actionsAA = n_actions[config[\"game_name\"]]\n",
    "game_action_type = 'discrete'\n",
    "\n",
    "# Load Autoencoder and Gaze Predictor\n",
    "ae_pattern = f'trained_models/autoencoder/AE_4f_TCDS_BlurPool64_{config[\"game_name\"]}_*.pkl'\n",
    "ae_files = glob.glob(ae_pattern)\n",
    "checkpoint_path = max(ae_files, key=os.path.getmtime)\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=True, map_location=device)\n",
    "autoencoder = Autoencoder(device).to(device)\n",
    "autoencoder.load_state_dict(checkpoint['state'])\n",
    "autoencoder.eval()\n",
    "\n",
    "GP_pattern = f'trained_models/gaze_predictor/gaze_predictor_4f_{config[\"game_name\"]}_*.pkl'\n",
    "GP_files = glob.glob(GP_pattern)\n",
    "GP_checkpoint_path = max(GP_files, key=os.path.getmtime)\n",
    "GP_checkpoint = torch.load(GP_checkpoint_path, weights_only=True, map_location=device)\n",
    "gaze_predictor = Gaze_predictor_pool(device, copy.deepcopy(autoencoder)).to(device)\n",
    "gaze_predictor.load_state_dict(GP_checkpoint['model_state'])\n",
    "gaze_predictor.eval()\n",
    "\n",
    "# Determine class weights\n",
    "for buffer_type, memory in zip(['AA', 'AH'], [memoryAA, memoryAH]):\n",
    "    if buffer_type == 'AA':\n",
    "        _, actions, _, _, _, _, done, _ = memory.sample_stacked(2048)\n",
    "    elif buffer_type == 'AH':\n",
    "        _, actions, _, _, _, _, done, _ = memory.sample_stacked(2048)\n",
    "\n",
    "    unique_values, counts = np.unique(actions[~done], return_counts=True)\n",
    "    for value, count in zip(unique_values, counts):\n",
    "        print(f\"Value: {value}, Frequency: {count}\")\n",
    "\n",
    "    class_weights = 1.0 / np.sqrt(counts)  # Inverse of class frequencies\n",
    "    class_weights = class_weights / class_weights.mean()  # Normalize (optional)\n",
    "\n",
    "    if buffer_type == 'AH':\n",
    "        ah_array = np.ones(18)\n",
    "    elif buffer_type == 'AA':\n",
    "        ah_array = np.ones(game_n_actionsAA)\n",
    "    for value, weight in zip(unique_values, class_weights):\n",
    "        ah_array[value] = weight\n",
    "    \n",
    "    class_weights = ah_array\n",
    "    class_weights = torch.tensor(class_weights, device=device, dtype=torch.float32)\n",
    "\n",
    "    if config[\"game_name\"] == 'Enduro' and buffer_type == 'AH':\n",
    "        class_weights[[2, 6, 7, 10, 13, 14, 15, 16, 17]] *= 0\n",
    "\n",
    "    if buffer_type == 'AA':\n",
    "        class_weightsAA = class_weights\n",
    "    elif buffer_type == 'AH':\n",
    "        class_weightsAH = class_weights\n",
    "\n",
    "# Initialize attention training network\n",
    "Att_network = Attention_training_class(\n",
    "    autoencoder, gaze_predictor, \n",
    "    action_dimAA=game_n_actionsAA, \n",
    "    action_dimAH=game_n_actionsAH, \n",
    "    lr=1e-3, \n",
    "    config=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training setup and execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup and execution\n",
    "cols = ['q-epoch', 'lr_MP', 'lr_CTR', 't:psi', 't:lam', 't:MP CTR', 't:MPacc CTR', 't:MP CTRf', 't:MPacc CTRf', 't:MP Plain', 't:MPacc Plain', 't:MP GP', 't:MPacc GP', 'v:psi', 'v:lam', 'v:MP CTR', 'v:MPacc CTR', 'v:MP CTRf', 'v:MPacc CTRf', 'v:MP Plain', 'v:MPacc Plain', 'v:MP GP', 'v:MPacc GP']\n",
    "\n",
    "df_AA = pd.DataFrame(columns=cols)\n",
    "df_AH = pd.DataFrame(columns=cols)\n",
    "\n",
    "batch_size = 128\n",
    "n_batches = 100\n",
    "\n",
    "j_epoch = 0\n",
    "tv_results_sum = 0\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Main training loop\n",
    "while j_epoch < config[\"n_epochs\"]:\n",
    "    all_batch_results = []  # Store each batch's results\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        tv_results = Att_network.train_AE_att(\n",
    "            j_epoch, memoryAA, memoryAH, batch_size, \n",
    "            config, class_weightsAA, class_weightsAH, \n",
    "            GP_comparison=False\n",
    "        )\n",
    "        all_batch_results.append(tv_results)  # Append the current batch results\n",
    "\n",
    "    all_batch_results = np.array(all_batch_results)\n",
    "    tv_results_mean = np.nanmean(all_batch_results, axis=0)  # Due to varying length of val samples, sometimes there are 0 leading to nan values\n",
    "\n",
    "    lr_MP_AA = get_lr(Att_network.MP_AA_optimizer)\n",
    "    lr_CTR_AA = get_lr(Att_network.CTR_AA_optimizer)\n",
    "    lr_MP_AH = get_lr(Att_network.MP_AH_optimizer)\n",
    "    lr_CTR_AH = get_lr(Att_network.CTR_AH_optimizer)\n",
    "\n",
    "    df_AA.loc[j_epoch] = [j_epoch+1, lr_MP_AA, lr_CTR_AA, *tv_results_mean[0, 0], *tv_results_mean[0, 1]]\n",
    "    df_AH.loc[j_epoch] = [j_epoch+1, lr_MP_AH, lr_CTR_AH, *tv_results_mean[1, 0], *tv_results_mean[1, 1]]\n",
    "    \n",
    "    clear_output()\n",
    "\n",
    "    print('Agent CTR results:')\n",
    "    print(df_AA.tail(5).drop([col for col in df_AA.columns if \"MPacc\" in col], axis=1).to_string(index=False))\n",
    "    print('\\nAgent CTR Accuracies:')\n",
    "    print(df_AA.tail(5).filter(like=\"MPacc\").to_string(index=False))\n",
    "    print('Human CTR results:')\n",
    "    print(df_AH.tail(5).drop([col for col in df_AH.columns if \"MPacc\" in col], axis=1).to_string(index=False))\n",
    "    print('\\nHuman CTR Accuracies:')\n",
    "    print(df_AH.tail(5).filter(like=\"MPacc\").to_string(index=False))\n",
    "\n",
    "    tv_results_sum = 0\n",
    "    v_results_sum = 0\n",
    "    GPc_results_sum = 0\n",
    "    \n",
    "    j_epoch += 1\n",
    "\n",
    "    memoryAA.shuffle_RAM()\n",
    "    memoryAH.shuffle_RAM()\n",
    "    print('Replay buffer RAM shuffled')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(8, 10))\n",
    "ravg = 1\n",
    "last = 1300\n",
    "\n",
    "# Define colors and data\n",
    "mpa_variants = ['MP CTR', 'MP Plain', 'MP GP']\n",
    "colors = [\"#2c81bd\", '#ff7f0e', '#2ca02c', '#d62728']  # Blue, Orange, Green, Red\n",
    "datasets = [('AA', 'b'), ('AH', 'r')]  # (name, color) pairs\n",
    "\n",
    "# Plot MPa variants for AA and AH\n",
    "for i, (name, color) in enumerate(datasets):\n",
    "    df = df_AA if name == 'AA' else df_AH\n",
    "    for j, variant in enumerate(mpa_variants):\n",
    "        ax[i].plot(df[f't:{variant}'].rolling(ravg).mean()[-last:],\n",
    "                  label=f'Train ({variant})', c=colors[j], alpha=0.8)\n",
    "        ax[i].plot(df[f'v:{variant}'].rolling(ravg).mean()[-last:],\n",
    "                  label=f'Val ({variant})', c=colors[j], linestyle='--', alpha=0.8)\n",
    "    ax[i].set_title(f'{name}: MPa Variants')\n",
    "    ax[i].legend(bbox_to_anchor=(1.05, 1))\n",
    "    ax[i].grid()\n",
    "\n",
    "# Plot psi for both AA and AH\n",
    "for name, color in datasets:\n",
    "    df = df_AA if name == 'AA' else df_AH\n",
    "    ax[2].plot(df['t:psi'].rolling(ravg).mean()[-last:],\n",
    "              label=f'{name}: Train', c=color)\n",
    "    ax[2].plot(df['v:psi'].rolling(ravg).mean()[-last:],\n",
    "              label=f'{name}: Val', c=color, linestyle='--')\n",
    "ax[2].set_title('Psi Comparison')\n",
    "ax[2].legend()\n",
    "ax[2].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Att_network.CTR_AA.eval()\n",
    "Att_network.CTR_AH.eval()\n",
    "n_frames = 512\n",
    "i_print = np.random.randint(batch_size)\n",
    "\n",
    "with torch.no_grad():\n",
    "    state_np, _, _, _, _, _, _, _ = memoryAH.sample_stacked(n_frames)\n",
    "    state = torch.tensor(state_np, device=device, dtype=torch.float32)/255*2-1\n",
    "    state_img = state_np.reshape(state_np.shape[0], state_np.shape[1], state_np.shape[2], -1)\n",
    "\n",
    "    lam = 0.02*torch.ones(n_frames, 1, device=device)\n",
    "    \n",
    "    psiAA = Att_network.CTR_AA.psi(state, lam)\n",
    "    psiAH = Att_network.CTR_AH.psi(state, lam)\n",
    "\n",
    "    kernel = func_a.make_gaussian_kernel(size=11, sigma=.7, device=device)\n",
    "    psiAA_blur = func_a.apply_gaussian_filter(psiAA, kernel)\n",
    "    psiAH_blur = func_a.apply_gaussian_filter(psiAH, kernel)\n",
    "\n",
    "    AA_heat = psiAA_blur.mean(axis=0).squeeze(0).detach().cpu().numpy()\n",
    "    AH_heat = psiAH_blur.mean(axis=0).squeeze(0).detach().cpu().numpy()\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "    ax[0, 0].imshow(state_img[i_print][..., -1])\n",
    "    ax[0, 0].set_title('Image')\n",
    "    \n",
    "    for idp, psi in enumerate([psiAA, psiAH]):\n",
    "        psi_np = psi[i_print].permute(1, 2, 0).cpu().detach().numpy()\n",
    "        psi_np_blur = scipy.ndimage.gaussian_filter(psi_np, sigma=0.0)\n",
    "        im = ax[1, idp].imshow(psi_np_blur)\n",
    "        fig.colorbar(im, ax=ax[1, idp], label='Attention score', fraction=0.046, pad=0.04)\n",
    "    \n",
    "    ax[0, 1].set_title('Gaze Predictor')\n",
    "    ax[1, 0].set_title('Agent CTR')\n",
    "    ax[1, 1].set_title('Human CTR')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "figh, axh = plt.subplots(1, 3, figsize=(8, 8))\n",
    "axh[0].imshow(AA_heat)\n",
    "axh[1].imshow(AH_heat)\n",
    "axh[0].set_title('Agent CTR Heatmap')\n",
    "axh[1].set_title('Human CTR Heatmap')\n",
    "axh[2].set_title('Gaze Heatmap')\n",
    "\n",
    "Att_network.CTR_AA.train()\n",
    "Att_network.CTR_AH.train()\n",
    "del psiAA, psiAH, psiAA_blur, psiAH_blur, AA_heat, AH_heat\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descr = 'V15'\n",
    "now = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "CTR_checkpoint = {\n",
    "    'CTR_AA_state': Att_network.CTR_AA.state_dict(),\n",
    "    'CTR_AA_opt_state': Att_network.CTR_AA_optimizer.state_dict(),\n",
    "    'CTR_AH_state': Att_network.CTR_AH.state_dict(),\n",
    "    'CTR_AH_opt_state': Att_network.CTR_AH_optimizer.state_dict(),\n",
    "    'MP_AA_state': Att_network.MP_AA.state_dict(),\n",
    "    'MP_AA_opt_state': Att_network.MP_AA_optimizer.state_dict(),\n",
    "    'MP_AH_state': Att_network.MP_AH.state_dict(),\n",
    "    'MP_AH_opt_state': Att_network.MP_AH_optimizer.state_dict(),\n",
    "    'MP_AA_plain_state': Att_network.MP_AA_plain.state_dict(),\n",
    "    'MP_AA_plain_opt_state': Att_network.MP_AA_plain_optimizer.state_dict(),    \n",
    "    'MP_AH_plain_state': Att_network.MP_AH_plain.state_dict(),\n",
    "    'MP_AH_plain_opt_state': Att_network.MP_AH_plain_optimizer.state_dict(),\n",
    "    'MP_AH_GP_state': Att_network.MP_AH_GP.state_dict(),\n",
    "    'MP_AH_GP_opt_state': Att_network.MP_AH_GP_optimizer.state_dict(),\n",
    "}\n",
    "\n",
    "with open(f'trained_models/CTR_att/nCTR_AA_AH_{model_descr}_{config[\"game_name\"]}_{now}.pkl', 'wb') as f:\n",
    "    torch.save(CTR_checkpoint, f)\n",
    "\n",
    "df_AA.to_csv(f'trained_models/CTR_att/nCTR_df_AA_{model_descr}_{config[\"game_name\"]}_{now}.csv', index=False) \n",
    "df_AH.to_csv(f'trained_models/CTR_att/nCTR_df_AH_{model_descr}_{config[\"game_name\"]}_{now}.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
